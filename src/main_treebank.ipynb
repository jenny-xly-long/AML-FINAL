{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from preprocess import preprocess_treebank\n",
    "from features_extract import features_extract\n",
    "import results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# loads data\n",
    "data = preprocess_treebank()\n",
    "X_train = data[0]\n",
    "y_train = data[1]\n",
    "X_test = data[2]\n",
    "y_test = data[3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# extract unigram binary features\n",
    "X_train_bin_uni, X_test_bin_uni = features_extract(X_train, X_test, type=\"binary\", ngram_range=(1,1))\n",
    "# extract unigram tfidf features\n",
    "X_train_tfidf_uni, X_test_tfidf_uni = features_extract(X_train, X_test, type=\"tf-idf\", ngram_range=(1,1))\n",
    "# extract bigram binary features\n",
    "X_train_bin_bi, X_test_bin_bi = features_extract(X_train, X_test, type=\"binary\", ngram_range=(1,2))\n",
    "# extract bigram tfidf features\n",
    "X_train_tfidf_bi, X_test_tfidf_bi = features_extract(X_train, X_test, type=\"tf-idf\", ngram_range=(1,2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load the equally weighted glove embeddings\n",
    "X_train_avg_embed_glove = np.genfromtxt('../data/X_treebank_train_embedded_avg_glove.csv', delimiter=\",\")\n",
    "X_test_avg_embed_glove = np.genfromtxt('../data/X_treebank_test_embedded_avg_glove.csv', delimiter=\",\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load the tf-idf weighted glove embeddings\n",
    "X_train_tfidf_embed_glove = np.genfromtxt('../data/X_treebank_train_embedded_tfidf_glove.csv', delimiter=\",\")\n",
    "X_test_tfidf_embed_glove = np.genfromtxt('../data/X_treebank_test_embedded_tfidf_glove.csv', delimiter=\",\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load the equally weighted spacy embeddings\n",
    "X_train_avg_embed_spacy = np.genfromtxt('../data/X_treebank_train_embedded_avg_spacy.csv', delimiter=\",\")\n",
    "X_test_avg_embed_spacy = np.genfromtxt('../data/X_treebank_test_embedded_avg_spacy.csv', delimiter=\",\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load the tf-idf weighted spacy embeddings\n",
    "X_train_tfidf_embed_spacy = np.genfromtxt('../data/X_treebank_train_embedded_tfidf_spacy.csv', delimiter=\",\")\n",
    "X_test_tfidf_embed_spacy = np.genfromtxt('../data/X_treebank_test_embedded_tfidf_spacy.csv', delimiter=\",\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "  > Logistic Regression: \n",
      "  > Evaluating...\n",
      "    Best parameters: {'C': 1, 'penalty': 'l2'} with score: 0.7884741479000011\n",
      "  > Training...\n",
      "  > Testing...\n",
      "    Test accuracy: 0.8132894014277869\n",
      "\n",
      "  > Linear SVM: \n",
      "  > Evaluating...\n",
      "    Best parameters: {'C': 1} with score: 0.7813330790047806\n",
      "  > Training...\n",
      "  > Testing...\n",
      "    Test accuracy: 0.7907742998352554\n",
      "\n",
      "  > Bernoulli Naive Bayes SVM: \n",
      "  > Evaluating...\n",
      "    Best parameters: {'C': 1, 'beta': 0.5} with score: 0.7905842801111098\n",
      "  > Training...\n",
      "  > Testing...\n",
      "    Test accuracy: 0.8204283360790774\n",
      "\n",
      "  > Multinomial Naive Bayes: \n",
      "  > Evaluating...\n",
      "    Best parameters: {'class_prior': (0.5, 0.5)} with score: 0.7820006914557528\n",
      "  > Training...\n",
      "  > Testing...\n",
      "    Test accuracy: 0.8220757825370676\n"
     ]
    }
   ],
   "source": [
    "# train and test the models on unigram binary features\n",
    "models_bin_uni = results.results(X_train_bin_uni, y_train, X_test_bin_uni, y_test, features = \"binary\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "  > Logistic Regression: \n",
      "  > Evaluating...\n",
      "    Best parameters: {'C': 1, 'penalty': 'l2'} with score: 0.7820960646630345\n",
      "  > Training...\n",
      "  > Testing...\n",
      "    Test accuracy: 0.7990115321252059\n",
      "\n",
      "  > Linear SVM: \n",
      "  > Evaluating...\n",
      "    Best parameters: {'C': 1} with score: 0.7754199401533124\n",
      "  > Training...\n",
      "  > Testing...\n",
      "    Test accuracy: 0.7742998352553542\n",
      "\n",
      "  > Bernoulli Naive Bayes SVM: \n",
      "  > Evaluating...\n",
      "    Best parameters: {'C': 100, 'beta': 0.75} with score: 0.7806893098556288\n",
      "  > Training...\n",
      "  > Testing...\n",
      "    Test accuracy: 0.8012081274025261\n",
      "\n",
      "  > Multinomial Naive Bayes: \n",
      "  > Evaluating...\n",
      "    Best parameters: {'class_prior': (0.5, 0.5)} with score: 0.7727971769530645\n",
      "  > Training...\n",
      "  > Testing...\n",
      "    Test accuracy: 0.8116419549697969\n"
     ]
    }
   ],
   "source": [
    "# train and test the models on bigram binary features\n",
    "models_bin_bi = results.results(X_train_bin_bi, y_train, X_test_bin_bi, y_test, features = \"binary\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "  > Logistic Regression: \n",
      "  > Evaluating...\n",
      "    Best parameters: {'C': 1, 'penalty': 'l2'} with score: 0.7885814427581932\n",
      "  > Training...\n",
      "  > Testing...\n",
      "    Test accuracy: 0.8209774848984075\n",
      "\n",
      "  > Linear SVM: \n",
      "  > Evaluating...\n",
      "    Best parameters: {'C': 1} with score: 0.7808204480156412\n",
      "  > Training...\n",
      "  > Testing...\n",
      "    Test accuracy: 0.8023064250411862\n",
      "\n",
      "  > Multinomial Naive Bayes: \n",
      "  > Evaluating...\n",
      "    Best parameters: {'class_prior': (0.5, 0.5)} with score: 0.7847784361178336\n",
      "  > Training...\n",
      "  > Testing...\n",
      "    Test accuracy: 0.8121911037891268\n"
     ]
    }
   ],
   "source": [
    "# train and test the models on unigram tf_idf features\n",
    "models_tfidf_uni = results.results(X_train_tfidf_uni, y_train, X_test_tfidf_uni, y_test, features = \"tf_idf\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "  > Logistic Regression: \n",
      "  > Evaluating...\n",
      "    Best parameters: {'C': 1, 'penalty': 'l2'} with score: 0.780152835564669\n",
      "  > Training...\n",
      "  > Testing...\n",
      "    Test accuracy: 0.8110928061504667\n",
      "\n",
      "  > Linear SVM: \n",
      "  > Evaluating...\n",
      "    Best parameters: {'C': 1} with score: 0.774907309164173\n",
      "  > Training...\n",
      "  > Testing...\n",
      "    Test accuracy: 0.7929708951125755\n",
      "\n",
      "  > Multinomial Naive Bayes: \n",
      "  > Evaluating...\n",
      "    Best parameters: {'class_prior': None} with score: 0.7764094371788606\n",
      "  > Training...\n",
      "  > Testing...\n",
      "    Test accuracy: 0.8110928061504667\n"
     ]
    }
   ],
   "source": [
    "# train and test the models on bigram tf_idf features\n",
    "models_tfidf_bi = results.results(X_train_tfidf_bi, y_train, X_test_tfidf_bi, y_test, features = \"tf_idf\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "  > Logistic Regression: \n",
      "  > Evaluating...\n",
      "    Best parameters: {'C': 1, 'penalty': 'l2'} with score: 0.7883310880890786\n",
      "  > Training...\n",
      "  > Testing...\n",
      "    Test accuracy: 0.7671609006040637\n",
      "\n",
      "  > Linear SVM: \n",
      "  > Evaluating...\n",
      "    Best parameters: {'C': 100} with score: 0.7877946137981188\n",
      "  > Training...\n",
      "  > Testing...\n",
      "    Test accuracy: 0.7688083470620538\n",
      "\n",
      "  > Feedforward NN:\n",
      "  > Training...\n",
      "WARNING:tensorflow:From C:\\Users\\Ayoub Elhanchi\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\op_def_library.py:263: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Colocations handled automatically by placer.\n",
      "WARNING:tensorflow:From C:\\Users\\Ayoub Elhanchi\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\ops\\math_ops.py:3066: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.cast instead.\n",
      "  > Testing...\n",
      "    Test accuracy: 0.7699066445370548\n",
      "\n",
      "  > Gaussian Naive Bayes: \n",
      "  > Evaluating...\n",
      "    Best parameters: {'priors': None} with score: 0.6125701887197339\n",
      "  > Training...\n",
      "  > Testing...\n",
      "    Test accuracy: 0.5403624382207578\n"
     ]
    }
   ],
   "source": [
    "# train and test the models on the equally weighted glove embeddings\n",
    "models_avg_embed_glove = results.results(X_train_avg_embed_glove, y_train, X_test_avg_embed_glove, y_test, features = \"sentence_embed\", D_in=200)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "  > Logistic Regression: \n",
      "  > Evaluating...\n",
      "    Best parameters: {'C': 1, 'penalty': 'l2'} with score: 0.7883310880890786\n",
      "  > Training...\n",
      "  > Testing...\n",
      "    Test accuracy: 0.7671609006040637\n",
      "\n",
      "  > Linear SVM: \n",
      "  > Evaluating...\n",
      "    Best parameters: {'C': 100} with score: 0.7877946137981188\n",
      "  > Training...\n",
      "  > Testing...\n",
      "    Test accuracy: 0.7688083470620538\n",
      "\n",
      "  > Feedforward NN:\n",
      "  > Training...\n",
      "  > Testing...\n",
      "    Test accuracy: 0.7764964300744289\n",
      "\n",
      "  > Gaussian Naive Bayes: \n",
      "  > Evaluating...\n",
      "    Best parameters: {'priors': None} with score: 0.6125701887197339\n",
      "  > Training...\n",
      "  > Testing...\n",
      "    Test accuracy: 0.5403624382207578\n"
     ]
    }
   ],
   "source": [
    "# train and test the models on the tfidf weighted glove embeddings\n",
    "models_tfidf_embed_glove = results.results(X_train_tfidf_embed_glove, y_train, X_test_tfidf_embed_glove, y_test, features = \"sentence_embed\", D_in=200)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "  > Logistic Regression: \n",
      "  > Evaluating...\n",
      "    Best parameters: {'C': 1, 'penalty': 'l1'} with score: 0.8259319750599063\n",
      "  > Training...\n",
      "  > Testing...\n",
      "    Test accuracy: 0.8094453596924767\n",
      "\n",
      "  > Linear SVM: \n",
      "  > Evaluating...\n",
      "    Best parameters: {'C': 0.01} with score: 0.827064531896377\n",
      "  > Training...\n",
      "  > Testing...\n",
      "    Test accuracy: 0.8088962108731467\n",
      "\n",
      "  > Feedforward NN:\n",
      "  > Training...\n",
      "  > Testing...\n",
      "    Test accuracy: 0.8110928065759805\n",
      "\n",
      "  > Gaussian Naive Bayes: \n",
      "  > Evaluating...\n",
      "    Best parameters: {'priors': (0.25, 0.75)} with score: 0.6677555107831332\n",
      "  > Training...\n",
      "  > Testing...\n",
      "    Test accuracy: 0.7660626029654036\n"
     ]
    }
   ],
   "source": [
    "# train and test the models on the equally weighted spacy embeddings\n",
    "models_avg_embed_spacy = results.results(X_train_avg_embed_spacy, y_train, X_test_avg_embed_spacy, y_test, features = \"sentence_embed\", D_in=300)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "  > Logistic Regression: \n",
      "  > Evaluating...\n",
      "    Best parameters: {'C': 1, 'penalty': 'l1'} with score: 0.8235595665287729\n",
      "  > Training...\n",
      "  > Testing...\n",
      "    Test accuracy: 0.7913234486545854\n",
      "\n",
      "  > Linear SVM: \n",
      "  > Evaluating...\n",
      "    Best parameters: {'C': 0.01} with score: 0.8240245109142714\n",
      "  > Training...\n",
      "  > Testing...\n",
      "    Test accuracy: 0.7907742998352554\n",
      "\n",
      "  > Feedforward NN:\n",
      "  > Training...\n",
      "  > Testing...\n",
      "    Test accuracy: 0.7984623834368032\n",
      "\n",
      "  > Gaussian Naive Bayes: \n",
      "  > Evaluating...\n",
      "    Best parameters: {'priors': (0.25, 0.75)} with score: 0.7170276939950644\n",
      "  > Training...\n",
      "  > Testing...\n",
      "    Test accuracy: 0.7468423942888522\n"
     ]
    }
   ],
   "source": [
    "# train and test the models on the tfidf weighted spacy embeddings\n",
    "models_tfidf_embed_spacy = results.results(X_train_tfidf_embed_spacy, y_train, X_test_tfidf_embed_spacy, y_test, features = \"sentence_embed\", D_in=300)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import importlib\n",
    "importlib.reload(results)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
