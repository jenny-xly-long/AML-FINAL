{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from preprocess import preprocess_twitter\n",
    "from features_extract import features_extract\n",
    "import results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# loads data\n",
    "data = preprocess_twitter(preprocess=True)\n",
    "X_train = data[0]\n",
    "y_train = data[1]\n",
    "X_test = data[2]\n",
    "y_test = data[3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# extract unigram binary features\n",
    "X_train_bin_uni, X_test_bin_uni = features_extract(X_train, X_test, type=\"binary\", ngram_range=(1,1))\n",
    "# extract unigram tfidf features\n",
    "X_train_tfidf_uni, X_test_tfidf_uni = features_extract(X_train, X_test, type=\"tf-idf\", ngram_range=(1,1))\n",
    "# extract bigram binary features\n",
    "X_train_bin_bi, X_test_bin_bi = features_extract(X_train, X_test, type=\"binary\", ngram_range=(1,2))\n",
    "# extract bigram tfidf features\n",
    "X_train_tfidf_bi, X_test_tfidf_bi = features_extract(X_train, X_test, type=\"tf-idf\", ngram_range=(1,2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load the equally weighted glove embeddings\n",
    "X_train_avg_embed_glove = np.genfromtxt('../data/X_twitter_train_embedded_avg_glove.csv', delimiter=\",\")\n",
    "X_test_avg_embed_glove = np.genfromtxt('../data/X_twitter_test_embedded_avg_glove.csv', delimiter=\",\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load the tf-idf weighted glove embeddings\n",
    "X_train_tfidf_embed_glove = np.genfromtxt('../data/X_twitter_train_embedded_tfidf_glove.csv', delimiter=\",\")\n",
    "X_test_tfidf_embed_glove = np.genfromtxt('../data/X_twitter_test_embedded_tfidf_glove.csv', delimiter=\",\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load the equally weighted spacy embeddings\n",
    "X_train_avg_embed_spacy = np.genfromtxt('../data/X_twitter_train_embedded_avg_spacy.csv', delimiter=\",\")\n",
    "X_test_avg_embed_spacy = np.genfromtxt('../data/X_twitter_test_embedded_avg_spacy.csv', delimiter=\",\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load the tf-idf weighted spacy embeddings\n",
    "X_train_tfidf_embed_spacy = np.genfromtxt('../data/X_twitter_train_embedded_tfidf_spacy.csv', delimiter=\",\")\n",
    "X_test_tfidf_embed_spacy = np.genfromtxt('../data/X_twitter_test_embedded_tfidf_spacy.csv', delimiter=\",\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "  > Logistic Regression: \n",
      "  > Evaluating...\n",
      "    Best parameters: {'C': 1, 'penalty': 'l1'} with score: 0.7741\n",
      "  > Training...\n",
      "  > Testing...\n",
      "    Test accuracy: 0.7966573816155988\n",
      "\n",
      "  > Linear SVM: \n",
      "  > Evaluating...\n",
      "    Best parameters: {'C': 0.01} with score: 0.774675\n",
      "  > Training...\n",
      "  > Testing...\n",
      "    Test accuracy: 0.7771587743732591\n",
      "\n",
      "  > Bernoulli Naive Bayes SVM: \n",
      "  > Evaluating...\n",
      "    Best parameters: {'C': 0.01, 'beta': 0.5} with score: 0.77775\n",
      "  > Training...\n",
      "  > Testing...\n",
      "    Test accuracy: 0.7827298050139275\n",
      "\n",
      "  > Multinomial Naive Bayes: \n",
      "  > Evaluating...\n",
      "    Best parameters: {'class_prior': None} with score: 0.7647875\n",
      "  > Training...\n",
      "  > Testing...\n",
      "    Test accuracy: 0.7799442896935933\n"
     ]
    }
   ],
   "source": [
    "# train and test the models on unigram binary features\n",
    "models_bin_uni = results.results(X_train_bin_uni, y_train, X_test_bin_uni, y_test, features = \"binary\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "  > Logistic Regression: \n",
      "  > Evaluating...\n",
      "    Best parameters: {'C': 1, 'penalty': 'l1'} with score: 0.7777\n",
      "  > Training...\n",
      "  > Testing...\n",
      "    Test accuracy: 0.7938718662952646\n",
      "\n",
      "  > Linear SVM: \n",
      "  > Evaluating...\n",
      "    Best parameters: {'C': 0.01} with score: 0.7785\n",
      "  > Training...\n",
      "  > Testing...\n",
      "    Test accuracy: 0.7883008356545961\n",
      "\n",
      "  > Bernoulli Naive Bayes SVM: \n",
      "  > Evaluating...\n",
      "    Best parameters: {'C': 0.01, 'beta': 0.5} with score: 0.78045\n",
      "  > Training...\n",
      "  > Testing...\n",
      "    Test accuracy: 0.7966573816155988\n",
      "\n",
      "  > Multinomial Naive Bayes: \n",
      "  > Evaluating...\n",
      "    Best parameters: {'class_prior': None} with score: 0.7662\n",
      "  > Training...\n",
      "  > Testing...\n",
      "    Test accuracy: 0.7855153203342619\n"
     ]
    }
   ],
   "source": [
    "# train and test the models on bigram binary features\n",
    "models_bin_bi = results.results(X_train_bin_bi, y_train, X_test_bin_bi, y_test, features = \"binary\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "  > Logistic Regression: \n",
      "  > Evaluating...\n",
      "    Best parameters: {'C': 1, 'penalty': 'l2'} with score: 0.7777125\n",
      "  > Training...\n",
      "  > Testing...\n",
      "    Test accuracy: 0.7855153203342619\n",
      "\n",
      "  > Linear SVM: \n",
      "  > Evaluating...\n",
      "    Best parameters: {'C': 1} with score: 0.76955\n",
      "  > Training...\n",
      "  > Testing...\n",
      "    Test accuracy: 0.7855153203342619\n",
      "\n",
      "  > Multinomial Naive Bayes: \n",
      "  > Evaluating...\n",
      "    Best parameters: {'class_prior': None} with score: 0.763575\n",
      "  > Training...\n",
      "  > Testing...\n",
      "    Test accuracy: 0.7883008356545961\n"
     ]
    }
   ],
   "source": [
    "# train and test the models on unigram tf_idf features\n",
    "models_tfidf_uni = results.results(X_train_tfidf_uni, y_train, X_test_tfidf_uni, y_test, features = \"tf_idf\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "  > Logistic Regression: \n",
      "  > Evaluating...\n",
      "    Best parameters: {'C': 1, 'penalty': 'l1'} with score: 0.7824625\n",
      "  > Training...\n",
      "  > Testing...\n",
      "    Test accuracy: 0.7827298050139275\n",
      "\n",
      "  > Linear SVM: \n",
      "  > Evaluating...\n",
      "    Best parameters: {'C': 1} with score: 0.7761375\n",
      "  > Training...\n",
      "  > Testing...\n",
      "    Test accuracy: 0.7994428969359332\n",
      "\n",
      "  > Multinomial Naive Bayes: \n",
      "  > Evaluating...\n",
      "    Best parameters: {'class_prior': None} with score: 0.769225\n",
      "  > Training...\n",
      "  > Testing...\n",
      "    Test accuracy: 0.8050139275766016\n"
     ]
    }
   ],
   "source": [
    "# train and test the models on bigram tf_idf features\n",
    "models_tfidf_bi = results.results(X_train_tfidf_bi, y_train, X_test_tfidf_bi, y_test, features = \"tf_idf\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "  > Logistic Regression: \n",
      "  > Evaluating...\n",
      "    Best parameters: {'C': 100, 'penalty': 'l2'} with score: 0.7459\n",
      "  > Training...\n",
      "  > Testing...\n",
      "    Test accuracy: 0.7604456824512534\n",
      "\n",
      "  > Linear SVM: \n",
      "  > Evaluating...\n",
      "    Best parameters: {'C': 100} with score: 0.7461\n",
      "  > Training...\n",
      "  > Testing...\n",
      "    Test accuracy: 0.7688022284122563\n",
      "\n",
      "  > Feedforward NN:\n",
      "  > Training...\n",
      "WARNING:tensorflow:From C:\\Users\\Ayoub Elhanchi\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\ops\\math_ops.py:3066: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.cast instead.\n",
      "  > Testing...\n",
      "    Test accuracy: 0.7715877365933155\n",
      "\n",
      "  > Gaussian Naive Bayes: \n",
      "  > Evaluating...\n",
      "    Best parameters: {'priors': (0.25, 0.75)} with score: 0.67975\n",
      "  > Training...\n",
      "  > Testing...\n",
      "    Test accuracy: 0.6991643454038997\n"
     ]
    }
   ],
   "source": [
    "# train and test the models on the equally weighted glove embeddings\n",
    "models_avg_embed_glove = results.results(X_train_avg_embed_glove, y_train, X_test_avg_embed_glove, y_test, features = \"sentence_embed\", D_in=200)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "  > Logistic Regression: \n",
      "  > Evaluating...\n",
      "    Best parameters: {'C': 100, 'penalty': 'l2'} with score: 0.7459\n",
      "  > Training...\n",
      "  > Testing...\n",
      "    Test accuracy: 0.7604456824512534\n",
      "\n",
      "  > Linear SVM: \n",
      "  > Evaluating...\n",
      "    Best parameters: {'C': 100} with score: 0.7461\n",
      "  > Training...\n",
      "  > Testing...\n",
      "    Test accuracy: 0.7688022284122563\n",
      "\n",
      "  > Feedforward NN:\n",
      "  > Training...\n",
      "  > Testing...\n",
      "    Test accuracy: 0.7660167192350191\n",
      "\n",
      "  > Gaussian Naive Bayes: \n",
      "  > Evaluating...\n",
      "    Best parameters: {'priors': (0.25, 0.75)} with score: 0.67975\n",
      "  > Training...\n",
      "  > Testing...\n",
      "    Test accuracy: 0.6991643454038997\n"
     ]
    }
   ],
   "source": [
    "# train and test the models on the tfidf weighted glove embeddings\n",
    "models_tfidf_embed_glove = results.results(X_train_tfidf_embed_glove, y_train, X_test_tfidf_embed_glove, y_test, features = \"sentence_embed\", D_in=200)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "  > Logistic Regression: \n",
      "  > Evaluating...\n",
      "    Best parameters: {'C': 100, 'penalty': 'l1'} with score: 0.761475\n",
      "  > Training...\n",
      "  > Testing...\n",
      "    Test accuracy: 0.8022284122562674\n",
      "\n",
      "  > Linear SVM: \n",
      "  > Evaluating...\n",
      "    Best parameters: {'C': 100} with score: 0.761075\n",
      "  > Training...\n",
      "  > Testing...\n",
      "    Test accuracy: 0.8022284122562674\n",
      "\n",
      "  > Feedforward NN:\n",
      "  > Training...\n",
      "  > Testing...\n",
      "    Test accuracy: 0.8245125353170305\n",
      "\n",
      "  > Gaussian Naive Bayes: \n",
      "  > Evaluating...\n",
      "    Best parameters: {'priors': (0.25, 0.75)} with score: 0.6693125\n",
      "  > Training...\n",
      "  > Testing...\n",
      "    Test accuracy: 0.6350974930362117\n"
     ]
    }
   ],
   "source": [
    "# train and test the models on the equally weighted spacy embeddings\n",
    "models_avg_embed_spacy = results.results(X_train_avg_embed_spacy, y_train, X_test_avg_embed_spacy, y_test, features = \"sentence_embed\", D_in=300)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "  > Logistic Regression: \n",
      "  > Evaluating...\n",
      "    Best parameters: {'C': 1, 'penalty': 'l1'} with score: 0.7421\n",
      "  > Training...\n",
      "  > Testing...\n",
      "    Test accuracy: 0.7520891364902507\n",
      "\n",
      "  > Linear SVM: \n",
      "  > Evaluating...\n",
      "    Best parameters: {'C': 1} with score: 0.7416875\n",
      "  > Training...\n",
      "  > Testing...\n",
      "    Test accuracy: 0.7520891364902507\n",
      "\n",
      "  > Feedforward NN:\n",
      "  > Training...\n",
      "  > Testing...\n",
      "    Test accuracy: 0.7688022289103452\n",
      "\n",
      "  > Gaussian Naive Bayes: \n",
      "  > Evaluating...\n",
      "    Best parameters: {'priors': (0.25, 0.75)} with score: 0.6272625\n",
      "  > Training...\n",
      "  > Testing...\n",
      "    Test accuracy: 0.6796657381615598\n"
     ]
    }
   ],
   "source": [
    "# train and test the models on the tfidf weighted spacy embeddings\n",
    "models_tfidf_embed_spacy = results.results(X_train_tfidf_embed_spacy, y_train, X_test_tfidf_embed_spacy, y_test, features = \"sentence_embed\", D_in=300)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<module 'feedforward_NN' from 'C:\\\\Users\\\\Ayoub Elhanchi\\\\Desktop\\\\Studies\\\\Winter 2019\\\\COMP 551\\\\Projects\\\\Project 4\\\\AML-FINAL\\\\src\\\\feedforward_NN.py'>"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import importlib\n",
    "importlib.reload(results)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
